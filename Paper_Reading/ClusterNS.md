# ClusterNS

[Clustering-Aware Negative Sampling for Unsupervised Sentence Representation](https://aclanthology.org/2023.findings-acl.555.pdf)

**论文发布之前的方法**：之前的方法主要依赖对比学习，集中于正样本的构造，而将批次中的其他样本简单视为负样本。这种处理忽略了选择合适负样本的重要性，可能导致难负样本的稀缺和误将假负样本排除在外。

**以前方法的缺点**：以前的方法存在两个主要问题：一是没有有效地挖掘难负样本，这对于模型学习更丰富的特征表示非常关键；二是可能误将与锚点样本相似度较高的假负样本作为真负样本处理，从而损害了模型的性能。

**这篇论文的创新点**：ClusterNS的创新之处在于结合了聚类信息和对比学习来改进负样本的选择。通过修改的K-means聚类算法在训练过程中提供难负样本，并识别批次中的假负样本，解决了之前方法中的两个主要问题。

**这篇论文的方法优点**：ClusterNS通过改进负样本的选择，提高了无监督句子表示学习的性能。实验结果表明，与基线方法相比，ClusterNS在语义文本相似性（STS）任务上取得了更好的结果，尤其是在处理假负样本和挖掘难负样本方面显示出其优越性。

**处理方式**：ClusterNS在每个小批量训练中应用修改后的K-means聚类算法，利用聚类结果提供额外的难负样本和识别假负样本，并使用双向边缘损失（BML）约束假负样本。