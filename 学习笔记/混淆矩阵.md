# 混淆矩阵（Confusion Matrix）

部分参考：[html](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)

## 一、什么是混淆矩阵？

|              | **True** | **False** |
| ------------ | -------- | --------- |
| **Positive** | TP       | FP        |
| **Negative** | TN       | FN        |

预测值的衡量是Positive和Negative

真实值的衡量是True和False

### 举例

在这里以是否怀孕为例，预测怀孕为阳性（Positive），预测未怀孕为阴性（Negative）![image-20240205133345203](.\src\pregnant)

#### True Positive

解释：模型正确的将正类预测为正类

例子：预测一个女人怀孕（Positive）了且她真的怀上了（True）

#### True Negative

解释：模型正确的将负类预测为负类

例子：预测一个男人没有怀孕（Negative）且他没有怀孕（True）

#### False Positive(第一种错误)

解释：模型错误的将负类预测为正类，也称为**误报**

例子：预测一个男人怀孕了（Positive）但是男人没有怀孕（False）

#### False Negative(第二种错误)

解释：模型错误的将正类预测为负类，被称为**漏报**

例子：预测一个女人没有怀孕（Negative）但是她实际上怀孕了（False）



## 二、为什么需要混淆矩阵？

用来衡量分类问题的预测性能

## 三、评估指标

### Recall（召回率）或Sensitivity（灵敏度）

$$
Recall=\frac{TP}{TP+FN}
$$



在所有实际为正类的样本中，被正确预测为正类的比例

### Precision（精确度）

$$
Precision=\frac{TP}{TP+FP}
$$

在所有被预测为正类的样本中，实际为正类的比例

### Accuracy（准确率）

$$
Accuracy=\frac{TP+TN}{TP+TN+FP+FN}
$$

所有被正确预测的样本（无论正类还是负类）占总样本的比例

### F1-Score

$$
F1=2\times\frac{Recall\times Precision}{Recall+Precision}
$$

F1分数是精确度和召回率的调和平均数（Harmonic Mean），是这两个指标的平衡度量。当需要同时考虑精确度和召回率时，可以选择参考F1



上述指标各有侧重点，选择哪些指标需要基于具体的应用场景。例如对于医疗诊断，漏诊（FN）的代价远远高于误诊（FP），因此需要更加注重召回率。而对于垃圾邮件检测，会更加关心精确度，避免将重要邮件错分为垃圾邮件





